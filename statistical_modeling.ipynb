{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78a7e322-8088-450a-abfb-a2b5530a10e6",
   "metadata": {},
   "source": [
    "# Titanic - Part 3: Predicting Survival with Statistical Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df53a6b-db9d-4d0c-af1e-b138c9ca5caa",
   "metadata": {},
   "source": [
    "## 1. Importing Dataset and Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f72821d-8401-4fd1-bca4-3a13e7985951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22b67a40-3ef4-4418-9ce6-18700eda64c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('testdata_after_eda.csv')\n",
    "df_test = data.copy()\n",
    "\n",
    "data = pd.read_csv('traindata_after_eda.csv')\n",
    "df_train = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a2656c9-6382-4428-adf5-922c877e21aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_template = pd.read_csv('gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb405a72-72a9-4f51-ad60-72231c1924a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   PassengerId     418 non-null    int64  \n",
      " 1   Pclass          418 non-null    int64  \n",
      " 2   Sex             418 non-null    object \n",
      " 3   Age             332 non-null    float64\n",
      " 4   Embarked        418 non-null    object \n",
      " 5   Nationality     418 non-null    object \n",
      " 6   Missing_Age     418 non-null    int64  \n",
      " 7   SharedTicket    418 non-null    int64  \n",
      " 8   Solo            418 non-null    int64  \n",
      " 9   IndividualFare  418 non-null    float64\n",
      " 10  DeckKnown       418 non-null    int64  \n",
      "dtypes: float64(2), int64(6), object(3)\n",
      "memory usage: 36.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ee1169a-f1ea-4876-9ef9-1fdcb5bafea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   PassengerId      891 non-null    int64  \n",
      " 1   Survived         891 non-null    int64  \n",
      " 2   Pclass           891 non-null    int64  \n",
      " 3   Sex              891 non-null    object \n",
      " 4   Age              714 non-null    float64\n",
      " 5   Embarked         891 non-null    object \n",
      " 6   Missing_Age      891 non-null    int64  \n",
      " 7   SharedTicket     891 non-null    int64  \n",
      " 8   TicketGroupSize  891 non-null    int64  \n",
      " 9   IndividualFare   891 non-null    float64\n",
      " 10  Solo             891 non-null    int64  \n",
      " 11  DeckKnown        891 non-null    int64  \n",
      "dtypes: float64(2), int64(8), object(2)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "115e25a0-bf4d-4d97-ba28-b0ee108a9c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   PassengerId  418 non-null    int64\n",
      " 1   Survived     418 non-null    int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 6.7 KB\n"
     ]
    }
   ],
   "source": [
    "df_template.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d54c3887-72e7-4fd8-8823-3c88d23d1cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_template['Survived'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874ac386-e0c9-436d-9b4b-58a64434d8d5",
   "metadata": {},
   "source": [
    "## 2. Training the Model using Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8151f16c-8a97-41bf-8226-6c5254150caa",
   "metadata": {},
   "source": [
    "For this project, we will use random forests. The training set will be used to train the model which will be applied to the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a77964f3-86be-4722-8a41-88912ab524c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns=['PassengerId', 'Survived'])\n",
    "y = df_train['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2bb3bb-c0b3-4926-b8eb-226bf65403eb",
   "metadata": {},
   "source": [
    "We are dealing with missing values and categorical features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201ef61d-a2e6-4c8f-8b2e-f77ec2577c8f",
   "metadata": {},
   "source": [
    "Quantitative features:\n",
    "- `Age`: continuous;\n",
    "- `IndividualFare`: continuous;\n",
    "- `TicketGroupSize`: discrete.\n",
    "\n",
    "Dummy features:\n",
    "- `Survived`;\n",
    "- `Missing_Age`;\n",
    "- `SharedTicket`;\n",
    "- `Solo`;\n",
    "- `DeckKnown`.\n",
    "\n",
    "Categorical features:\n",
    "- `Pclass`;\n",
    "- `Sex`;\n",
    "- `Embarked`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af70a84-f69b-486b-93fa-eb3e571ea738",
   "metadata": {},
   "source": [
    "The dummy features are good the way they are. The categorical features that have not been encoded yet will need some attention. The missing values are in the `Age` column. They will be imputed using means. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012c7a8c-1917-4bf3-9d36-76041c2f2203",
   "metadata": {},
   "source": [
    "We will create a preprocessing pipeline to deal with the missing values and the categorical features. We can later use this pipeline when training the model. We want the imputation to be performed without suffering from data leakage, so within the folds of the cross validation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e940bfdf-e3e7-491e-8a01-bf5b7634ee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['Pclass', 'Sex', 'Embarked']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='mean'), ['Age']),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b551210-8ab1-432f-9f30-a901add5a6f0",
   "metadata": {},
   "source": [
    "The preprocessor and the XGBoost are combined in a pipeline for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64d459ea-ed37-4ce6-91ef-8cde9fe2919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', XGBClassifier(eval_metric='logloss', random_state=0))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ef36d4-37a1-40ff-9a42-bf97bf6ca529",
   "metadata": {},
   "source": [
    "There are some hyperparameters in the boosting model. We will tune the parameters for the maximum depth and the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c9ecd42-71f1-4e9e-b818-3363e915bc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    'classifier__max_depth': randint(3, 10),\n",
    "    'classifier__learning_rate': uniform(0.01, 0.3)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14e8597-e3a8-4566-813e-2140416c3d86",
   "metadata": {},
   "source": [
    "We will perform randomized search to tune the hyperparameters during the cross-validation process. This means that there will be 20 iterations in which random combinations of hyperparameter values will be used to train the boosting model. These random values come from the ranges defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f84e313-c92f-4ca0-85e7-0010fa8dc9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d53c7f0-400a-4414-bace-d766a70ceca9",
   "metadata": {},
   "source": [
    "We can now perform the random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "701c31c4-4914-4e74-b52e-5a9d95bd4fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30bc1959-caa9-4918-b3cc-6f3794ef2b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = random_search.predict(df_test.drop(columns=['PassengerId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "063389fe-9c0a-4225-b820-de9b493f335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_template['Survived'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d45523c-2f1e-4c4f-817d-f5f465328683",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_template.to_csv(\"titanic_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
